{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W4_Clustering Text Data with Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import spdiags\n",
    "from scipy.stats import multivariate_normal\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Digby_Morrell&gt;</td>\n",
       "      <td>Digby Morrell</td>\n",
       "      <td>digby morrell born 10 october 1979 is a former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Alfred_J._Lewy&gt;</td>\n",
       "      <td>Alfred J. Lewy</td>\n",
       "      <td>alfred j lewy aka sandy lewy graduated from un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Harpdog_Brown&gt;</td>\n",
       "      <td>Harpdog Brown</td>\n",
       "      <td>harpdog brown is a singer and harmonica player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Franz_Rottensteiner&gt;</td>\n",
       "      <td>Franz Rottensteiner</td>\n",
       "      <td>franz rottensteiner born in waidmannsfeld lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/G-Enka&gt;</td>\n",
       "      <td>G-Enka</td>\n",
       "      <td>henry krvits born 30 december 1974 in tallinn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URI                 name  \\\n",
       "0        <http://dbpedia.org/resource/Digby_Morrell>        Digby Morrell   \n",
       "1       <http://dbpedia.org/resource/Alfred_J._Lewy>       Alfred J. Lewy   \n",
       "2        <http://dbpedia.org/resource/Harpdog_Brown>        Harpdog Brown   \n",
       "3  <http://dbpedia.org/resource/Franz_Rottensteiner>  Franz Rottensteiner   \n",
       "4               <http://dbpedia.org/resource/G-Enka>               G-Enka   \n",
       "\n",
       "                                                text  \n",
       "0  digby morrell born 10 october 1979 is a former...  \n",
       "1  alfred j lewy aka sandy lewy graduated from un...  \n",
       "2  harpdog brown is a singer and harmonica player...  \n",
       "3  franz rottensteiner born in waidmannsfeld lowe...  \n",
       "4  henry krvits born 30 december 1974 in tallinn ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('people_wiki.csv').head(5000) # 5000 * 3\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5000x100282 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 881415 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    data = loader['data']\n",
    "    indices = loader['indices']\n",
    "    indptr = loader['indptr']\n",
    "    shape = loader['shape']\n",
    "    return csr_matrix( (data, indices, indptr), shape)\n",
    "\n",
    "tf_idf_matrix = load_sparse_csr('4_tf_idf.npz')\n",
    "tf_idf_matrix = normalize(tf_idf_matrix)\n",
    "tf_idf_matrix # sparse matrix with 5000 data points, 100282 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93320</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90689</th>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88780</th>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14059</th>\n",
       "      <td>000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29242</th>\n",
       "      <td>0006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word\n",
       "word_index        \n",
       "93320            0\n",
       "90689           00\n",
       "88780          000\n",
       "14059       000577\n",
       "29242         0006"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.read_json('4_map_index_to_word.json', typ='series')\n",
    "map_index_to_word = pd.DataFrame(ser, columns=['word_index'])\n",
    "map_index_to_word['word'] = map_index_to_word.index\n",
    "map_index_to_word.index = map_index_to_word['word_index']\n",
    "map_index_to_word.drop('word_index', axis=1, inplace=True)\n",
    "map_index_to_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log probability function for diagonal covariance Gaussian\n",
    "def diag(array):\n",
    "    n = len(array)\n",
    "    return spdiags(array, 0, n, n)\n",
    "\n",
    "def logpdf_diagonal_gaussian(x, mean, cov):\n",
    "    '''\n",
    "    Compute logpdf of a multivariate Gaussian distribution with diagonal covariance at a given point x.\n",
    "    A multivariate Gaussian distribution with a diagonal covariance is equivalent\n",
    "    to a collection of independent Gaussian random variables.\n",
    "\n",
    "    x should be a sparse matrix. The logpdf will be computed for each row of x.\n",
    "    mean and cov should be given as 1D numpy arrays\n",
    "    mean[i] : mean of i-th variable\n",
    "    cov[i] : variance of i-th variable\n",
    "    '''\n",
    "\n",
    "    n = x.shape[0]\n",
    "    dim = x.shape[1]\n",
    "    assert(dim == len(mean) and dim == len(cov))\n",
    "\n",
    "    scaled_x = x.dot( diag(1./(2*np.sqrt(cov))) )\n",
    "    scaled_mean = mean/(2*np.sqrt(cov))\n",
    "\n",
    "    return -np.sum(np.log(np.sqrt(2*np.pi*cov))) - pairwise_distances(scaled_x, [scaled_mean], 'euclidean').flatten()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EM algorithm for sparse data\n",
    "def log_sum_exp(x, axis):\n",
    "    '''Compute the log of a sum of exponentials'''\n",
    "    x_max = np.max(x, axis=axis)\n",
    "    if axis == 1:\n",
    "        return x_max + np.log(np.sum(np.exp(x-x_max[:,np.newaxis]), axis=1))\n",
    "    else:\n",
    "        return x_max + np.log(np.sum(np.exp(x-x_max), axis=0))\n",
    "\n",
    "def EM_for_high_dimension(data, means, covs, weights, cov_smoothing=1e-5, maxiter=int(1e3), thresh=1e-4, verbose=False):\n",
    "    n = data.shape[0]\n",
    "    dim = data.shape[1]\n",
    "    mu = deepcopy(means)\n",
    "    Sigma = deepcopy(covs)\n",
    "    K = len(mu)\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    ll = None\n",
    "    ll_trace = []\n",
    "\n",
    "    for i in range(maxiter):\n",
    "        # E-step: compute responsibilities\n",
    "        logresp = np.zeros((n,K))\n",
    "        for k in range(K):\n",
    "            logresp[:,k] = np.log(weights[k]) + logpdf_diagonal_gaussian(data, mu[k], Sigma[k])\n",
    "        ll_new = np.sum(log_sum_exp(logresp, axis=1))\n",
    "        if verbose:\n",
    "            print(ll_new)\n",
    "        logresp -= np.vstack(log_sum_exp(logresp, axis=1))\n",
    "        resp = np.exp(logresp)\n",
    "        counts = np.sum(resp, axis=0)\n",
    "\n",
    "        # M-step: update weights, means, covariances\n",
    "        weights = counts / np.sum(counts)\n",
    "        for k in range(K):\n",
    "            mu[k] = (diag(resp[:,k]).dot(data)).sum(axis=0)/counts[k]\n",
    "            mu[k] = mu[k].A1\n",
    "\n",
    "            Sigma[k] = diag(resp[:,k]).dot( data.multiply(data)-2*data.dot(diag(mu[k])) ).sum(axis=0) + (mu[k]**2)*counts[k]\n",
    "            Sigma[k] = Sigma[k].A1 / counts[k] + cov_smoothing*np.ones(dim)\n",
    "\n",
    "        # check for convergence in log-likelihood\n",
    "        ll_trace.append(ll_new)\n",
    "        if ll is not None and (ll_new-ll) < thresh and ll_new > -np.inf:\n",
    "            ll = ll_new\n",
    "            break\n",
    "        else:\n",
    "            ll = ll_new\n",
    "\n",
    "    out = {'weights':weights, 'means':mu, 'covs':Sigma, 'loglik':ll_trace, 'resp':resp}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize mean parameters using k-means\n",
    "np.random.seed(5)\n",
    "num_clusters = 25\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=num_clusters, n_init=5, max_iter=400, random_state=1, n_jobs=-1).fit(tf_idf_matrix)\n",
    "centroids, cluster_assignment = kmeans_model.cluster_centers_, kmeans_model.labels_\n",
    "\n",
    "means = [centroid for centroid in centroids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         2.01954039e-04,   1.04447276e-04,   9.87192763e-05])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize cluster weights\n",
    "num_docs = tf_idf_matrix.shape[0]\n",
    "weights = []\n",
    "for i in range(num_clusters):\n",
    "    num_assigned = sum(cluster_assignment==i) # compute the number of data points assigned to cluster i\n",
    "    w = float(num_assigned) / num_docs\n",
    "    weights.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize covariances\n",
    "covs = []\n",
    "for i in range(num_clusters):\n",
    "    member_rows = tf_idf_matrix[cluster_assignment==i]\n",
    "    cov = (member_rows.multiply(member_rows) - 2*member_rows.dot(diag(means[i]))).sum(axis=0).A1 / member_rows.shape[0] + means[i]**2\n",
    "    cov[cov < 1e-8] = 1e-8\n",
    "    covs.append(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100282"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3855847476.7012835, 4844053202.46348, 4844053202.46348]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = EM_for_high_dimension(tf_idf_matrix, means, covs, weights, cov_smoothing=1e-10)\n",
    "out['loglik'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_EM_clusters(tf_idf_matrix, means, covs, map_index_to_word):\n",
    "    num_clusters = len(means)\n",
    "    for c in range(num_clusters):\n",
    "        print('')\n",
    "        print('==========================================================')\n",
    "        print('Cluster {0:d}: Largest mean parameters in cluster '.format(c))\n",
    "        print('{0: <12}{1: <12}{2: <12}'.format('Word', 'Mean', 'Variance'))\n",
    "        \n",
    "        # The k'th element of sorted_word_ids should be the index of the word \n",
    "        # that has the k'th-largest value in the cluster mean. Hint: Use np.argsort().\n",
    "        sorted_word_ids = np.argsort(means[c])\n",
    "    \n",
    "        for i in sorted_word_ids[-5:]:\n",
    "            print('{0: <12}{1: <10.2e}{2: <10.2e}'.format(map_index_to_word.loc[i]['word'], means[c][i], covs[c][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "Cluster 0: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "elected     2.91e-02  8.95e-04  \n",
      "liberal     2.93e-02  4.55e-03  \n",
      "party       5.89e-02  2.61e-03  \n",
      "election    5.89e-02  3.21e-03  \n",
      "minister    7.57e-02  7.42e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 1: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "directed    3.39e-02  2.22e-03  \n",
      "feature     3.69e-02  1.81e-03  \n",
      "festival    4.66e-02  3.60e-03  \n",
      "films       5.50e-02  2.97e-03  \n",
      "film        1.76e-01  6.07e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 2: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "design      3.20e-02  4.59e-03  \n",
      "artist      3.61e-02  1.44e-03  \n",
      "gallery     3.65e-02  3.40e-03  \n",
      "museum      5.62e-02  7.27e-03  \n",
      "art         1.26e-01  6.83e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 3: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "team        4.68e-02  1.30e-03  \n",
      "coach       5.57e-02  5.91e-03  \n",
      "points      6.25e-02  5.92e-03  \n",
      "nba         1.01e-01  1.22e-02  \n",
      "basketball  1.86e-01  7.78e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 4: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "league      4.31e-02  1.53e-03  \n",
      "season      5.05e-02  2.52e-03  \n",
      "ice         6.40e-02  2.97e-03  \n",
      "nhl         1.56e-01  1.64e-02  \n",
      "hockey      2.45e-01  1.64e-02  \n",
      "\n",
      "==========================================================\n",
      "Cluster 5: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "democratic  4.46e-02  3.02e-03  \n",
      "district    4.60e-02  2.37e-03  \n",
      "house       4.64e-02  2.41e-03  \n",
      "senate      5.41e-02  6.28e-03  \n",
      "republican  7.93e-02  5.20e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 6: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "womens      1.21e-02  1.46e-03  \n",
      "women       1.43e-02  1.36e-03  \n",
      "miss        2.22e-02  7.76e-03  \n",
      "her         1.00e-01  3.14e-03  \n",
      "she         1.60e-01  4.65e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 7: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "she         4.18e-02  5.99e-03  \n",
      "medal       4.28e-02  2.44e-03  \n",
      "olympics    4.69e-02  2.59e-03  \n",
      "m           4.70e-02  7.58e-03  \n",
      "championships7.78e-02  5.17e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 8: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "he          1.04e-02  6.05e-05  \n",
      "novel       1.07e-02  1.43e-03  \n",
      "that        1.10e-02  1.73e-04  \n",
      "published   1.23e-02  6.16e-04  \n",
      "book        1.45e-02  9.38e-04  \n",
      "\n",
      "==========================================================\n",
      "Cluster 9: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "drama       5.03e-02  6.40e-03  \n",
      "film        5.98e-02  3.44e-03  \n",
      "actress     7.65e-02  4.29e-03  \n",
      "her         8.99e-02  2.74e-03  \n",
      "she         1.37e-01  4.25e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 10: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "league      3.07e-02  2.01e-03  \n",
      "coach       3.09e-02  4.45e-03  \n",
      "team        4.13e-02  2.15e-03  \n",
      "chess       4.52e-02  1.66e-02  \n",
      "soccer      1.15e-01  2.86e-02  \n",
      "\n",
      "==========================================================\n",
      "Cluster 11: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "executive   2.15e-02  1.23e-03  \n",
      "served      2.24e-02  6.99e-04  \n",
      "committee   2.34e-02  2.38e-03  \n",
      "chairman    2.44e-02  1.97e-03  \n",
      "president   2.52e-02  1.29e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 12: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "chinese     3.12e-02  5.33e-03  \n",
      "kong        3.50e-02  8.64e-03  \n",
      "hong        3.78e-02  9.92e-03  \n",
      "jazz        6.07e-02  1.14e-02  \n",
      "music       7.26e-02  3.48e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 13: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "studies     2.41e-02  1.95e-03  \n",
      "professor   2.74e-02  1.08e-03  \n",
      "philosophy  2.86e-02  5.35e-03  \n",
      "history     3.38e-02  2.81e-03  \n",
      "university  3.47e-02  8.89e-04  \n",
      "\n",
      "==========================================================\n",
      "Cluster 14: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "comedy      2.86e-02  3.91e-03  \n",
      "film        2.93e-02  1.16e-03  \n",
      "television  3.21e-02  1.67e-03  \n",
      "actor       3.56e-02  2.91e-03  \n",
      "theatre     4.93e-02  6.17e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 15: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "song        2.50e-02  1.81e-03  \n",
      "released    3.13e-02  1.11e-03  \n",
      "music       4.18e-02  1.96e-03  \n",
      "band        5.35e-02  4.21e-03  \n",
      "album       6.76e-02  4.78e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 16: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "formula     6.06e-02  1.31e-02  \n",
      "championship6.27e-02  4.54e-03  \n",
      "racing      8.45e-02  8.26e-03  \n",
      "pga         1.08e-01  2.65e-02  \n",
      "tour        1.14e-01  1.92e-02  \n",
      "\n",
      "==========================================================\n",
      "Cluster 17: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "chef        3.27e-02  1.18e-02  \n",
      "bbc         3.63e-02  7.41e-03  \n",
      "show        3.75e-02  2.56e-03  \n",
      "radio       5.18e-02  4.62e-03  \n",
      "news        5.76e-02  8.06e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 18: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "quarterback 4.02e-02  7.16e-03  \n",
      "coach       6.74e-02  7.85e-03  \n",
      "nfl         6.98e-02  9.15e-03  \n",
      "yards       7.37e-02  1.72e-02  \n",
      "football    1.11e-01  5.60e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 19: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "cup         4.22e-02  2.46e-03  \n",
      "rugby       4.35e-02  8.18e-03  \n",
      "season      4.77e-02  2.30e-03  \n",
      "club        5.04e-02  2.64e-03  \n",
      "league      5.21e-02  3.13e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 20: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "philharmonic4.96e-02  3.27e-03  \n",
      "conductor   8.16e-02  1.01e-02  \n",
      "symphony    8.70e-02  1.08e-02  \n",
      "music       1.23e-01  6.15e-03  \n",
      "orchestra   1.31e-01  1.06e-02  \n",
      "\n",
      "==========================================================\n",
      "Cluster 21: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "district    3.72e-02  4.20e-03  \n",
      "attorney    3.74e-02  4.30e-03  \n",
      "judge       4.59e-02  4.44e-03  \n",
      "court       6.84e-02  5.24e-03  \n",
      "law         9.52e-02  8.35e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 22: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "season      5.58e-02  1.83e-03  \n",
      "club        5.93e-02  1.76e-03  \n",
      "australian  7.91e-02  1.58e-03  \n",
      "afl         9.58e-02  1.31e-02  \n",
      "football    1.21e-01  6.14e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 23: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "physics     2.61e-02  5.43e-03  \n",
      "professor   3.20e-02  1.26e-03  \n",
      "university  3.34e-02  7.14e-04  \n",
      "science     3.50e-02  2.95e-03  \n",
      "research    5.70e-02  2.68e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 24: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "sox         4.55e-02  6.28e-03  \n",
      "games       4.66e-02  1.93e-03  \n",
      "major       5.09e-02  1.19e-03  \n",
      "league      1.03e-01  3.63e-03  \n",
      "baseball    1.16e-01  5.57e-03  \n"
     ]
    }
   ],
   "source": [
    "visualize_EM_clusters(tf_idf_matrix, out['means'], out['covs'], map_index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare to random initialization\n",
    "np.random.seed(5)\n",
    "num_clusters = len(means)\n",
    "num_docs, num_words = tf_idf_matrix.shape\n",
    "\n",
    "random_means = []\n",
    "random_covs = []\n",
    "random_weights = []\n",
    "\n",
    "for k in range(num_clusters):\n",
    "    \n",
    "    # create a numpy array of length num_words with random normally distributed values\n",
    "    mean = np.random.normal(0.0, 1.0, num_words)\n",
    "    # create a numpy array of length num_words with random values uniformly distributed between 1 and 5.\n",
    "    cov = np.random.uniform(1.0, 5.0, num_words)\n",
    "    # initially give each cluster equal weight\n",
    "    weight = 1 / num_clusters\n",
    "\n",
    "    random_means.append(mean)\n",
    "    random_covs.append(cov)\n",
    "    random_weights.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_init_out = EM_for_high_dimension(tf_idf_matrix, random_means, random_covs, random_weights, cov_smoothing=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-764085987.57300639,\n",
       " 2282866699.1732855,\n",
       " 2362585588.3564939,\n",
       " 2362875609.1670547,\n",
       " 2362875609.1670547]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_init_out['loglik']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "Cluster 0: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "bbc         1.20e-02  1.82e-03  \n",
      "singapore   1.80e-02  5.72e-03  \n",
      "music       2.03e-02  2.37e-03  \n",
      "her         2.63e-02  1.82e-03  \n",
      "she         4.21e-02  5.79e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 1: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "league      1.04e-02  9.58e-04  \n",
      "music       1.05e-02  9.94e-04  \n",
      "university  1.06e-02  3.19e-04  \n",
      "she         1.29e-02  1.67e-03  \n",
      "he          1.38e-02  1.11e-04  \n",
      "\n",
      "==========================================================\n",
      "Cluster 2: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "festival    1.06e-02  2.02e-03  \n",
      "he          1.13e-02  1.20e-04  \n",
      "music       1.46e-02  1.42e-03  \n",
      "her         2.43e-02  2.57e-03  \n",
      "she         3.30e-02  3.96e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 3: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "he          1.00e-02  9.16e-05  \n",
      "series      1.04e-02  5.20e-04  \n",
      "film        1.43e-02  2.01e-03  \n",
      "her         1.76e-02  1.50e-03  \n",
      "she         2.69e-02  3.29e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 4: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "university  1.05e-02  2.92e-04  \n",
      "he          1.24e-02  1.13e-04  \n",
      "her         1.47e-02  1.28e-03  \n",
      "music       1.54e-02  1.69e-03  \n",
      "she         2.59e-02  3.38e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 5: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "season      1.59e-02  9.47e-04  \n",
      "baseball    1.79e-02  2.28e-03  \n",
      "league      2.15e-02  2.54e-03  \n",
      "her         2.18e-02  2.47e-03  \n",
      "she         2.73e-02  3.73e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 6: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "air         1.08e-02  3.75e-03  \n",
      "league      1.09e-02  1.05e-03  \n",
      "art         1.87e-02  4.07e-03  \n",
      "her         2.92e-02  3.00e-03  \n",
      "she         3.16e-02  3.84e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 7: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "he          1.10e-02  1.04e-04  \n",
      "poker       1.14e-02  6.38e-03  \n",
      "university  1.27e-02  4.92e-04  \n",
      "her         1.64e-02  1.50e-03  \n",
      "she         2.67e-02  3.61e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 8: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "hockey      1.65e-02  6.31e-03  \n",
      "team        1.66e-02  9.01e-04  \n",
      "season      1.82e-02  1.25e-03  \n",
      "she         1.83e-02  2.55e-03  \n",
      "league      2.46e-02  2.44e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 9: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "minister    1.00e-02  1.21e-03  \n",
      "university  1.28e-02  3.66e-04  \n",
      "he          1.38e-02  1.23e-04  \n",
      "her         1.70e-02  1.81e-03  \n",
      "she         2.35e-02  2.81e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 10: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "university  1.33e-02  4.72e-04  \n",
      "district    1.39e-02  1.71e-03  \n",
      "chess       1.55e-02  6.60e-03  \n",
      "her         2.11e-02  1.96e-03  \n",
      "she         2.82e-02  3.37e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 11: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "he          1.30e-02  1.11e-04  \n",
      "music       1.30e-02  9.98e-04  \n",
      "album       1.33e-02  1.98e-03  \n",
      "her         1.49e-02  1.77e-03  \n",
      "she         1.96e-02  2.49e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 12: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "party       1.15e-02  1.04e-03  \n",
      "he          1.20e-02  1.15e-04  \n",
      "film        1.59e-02  2.26e-03  \n",
      "her         2.10e-02  1.98e-03  \n",
      "she         3.42e-02  4.59e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 13: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "president   9.84e-03  3.93e-04  \n",
      "her         1.04e-02  9.32e-04  \n",
      "university  1.27e-02  5.70e-04  \n",
      "he          1.27e-02  9.42e-05  \n",
      "she         1.95e-02  3.20e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 14: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "band        1.44e-02  1.93e-03  \n",
      "she         1.48e-02  2.05e-03  \n",
      "kong        1.94e-02  5.53e-03  \n",
      "hong        2.03e-02  6.13e-03  \n",
      "law         2.41e-02  5.18e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 15: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "season      1.18e-02  8.20e-04  \n",
      "music       1.30e-02  1.10e-03  \n",
      "he          1.35e-02  1.08e-04  \n",
      "she         1.49e-02  2.10e-03  \n",
      "league      1.63e-02  1.76e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 16: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "baseball    1.18e-02  2.13e-03  \n",
      "music       1.19e-02  1.26e-03  \n",
      "research    1.20e-02  1.17e-03  \n",
      "science     1.26e-02  2.19e-03  \n",
      "film        2.09e-02  3.65e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 17: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "her         1.54e-02  9.90e-04  \n",
      "music       1.63e-02  1.25e-03  \n",
      "symphony    1.71e-02  4.89e-03  \n",
      "orchestra   1.83e-02  4.74e-03  \n",
      "she         2.87e-02  3.67e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 18: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "film        1.24e-02  1.67e-03  \n",
      "championship1.26e-02  2.12e-03  \n",
      "he          1.41e-02  1.33e-04  \n",
      "music       2.05e-02  2.45e-03  \n",
      "she         2.50e-02  4.52e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 19: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "taylor      1.13e-02  3.93e-03  \n",
      "served      1.15e-02  4.49e-04  \n",
      "her         1.22e-02  1.08e-03  \n",
      "he          1.28e-02  1.20e-04  \n",
      "she         2.62e-02  4.08e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 20: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "australian  1.13e-02  1.90e-03  \n",
      "he          1.15e-02  9.46e-05  \n",
      "her         1.16e-02  9.68e-04  \n",
      "health      1.34e-02  3.64e-03  \n",
      "she         2.37e-02  4.14e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 21: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "his         9.58e-03  7.85e-05  \n",
      "football    9.61e-03  1.29e-03  \n",
      "she         1.19e-02  1.71e-03  \n",
      "university  1.22e-02  3.46e-04  \n",
      "he          1.35e-02  9.19e-05  \n",
      "\n",
      "==========================================================\n",
      "Cluster 22: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "music       1.10e-02  1.27e-03  \n",
      "her         1.19e-02  1.47e-03  \n",
      "he          1.39e-02  1.05e-04  \n",
      "she         1.51e-02  2.41e-03  \n",
      "church      1.71e-02  3.31e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 23: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "he          1.19e-02  1.22e-04  \n",
      "music       1.52e-02  1.40e-03  \n",
      "album       1.74e-02  3.15e-03  \n",
      "her         2.08e-02  1.92e-03  \n",
      "she         3.39e-02  5.30e-03  \n",
      "\n",
      "==========================================================\n",
      "Cluster 24: Largest mean parameters in cluster \n",
      "Word        Mean        Variance    \n",
      "season      1.18e-02  7.78e-04  \n",
      "he          1.22e-02  9.16e-05  \n",
      "football    1.31e-02  2.31e-03  \n",
      "played      1.36e-02  6.66e-04  \n",
      "she         1.73e-02  2.63e-03  \n"
     ]
    }
   ],
   "source": [
    "visualize_EM_clusters(tf_idf_matrix, random_init_out['means'], random_init_out['covs'], map_index_to_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
